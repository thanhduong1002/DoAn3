<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>How to use Operators with AWS Controllers for Kubernetes</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/05/16/how-use-operators-aws-controllers-kubernetes" /><author><name>August Simonelli</name></author><id>481f182a-39a9-486b-9e0c-8425aec05234</id><updated>2022-05-16T07:00:00Z</updated><published>2022-05-16T07:00:00Z</published><summary type="html">&lt;p&gt;This is the first of two articles that show how to simplify the management of services offered for &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; by Amazon Web Services (AWS), through the use of &lt;a href="https://gallery.ecr.aws/aws-controllers-k8s"&gt;Amazon's AWS Controllers for Kubernetes&lt;/a&gt; (ACK). You'll also learn how to use an &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/"&gt;Operator&lt;/a&gt; to simplify installation further on &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; clusters. Together, these tools provide standardized and familiar interfaces to AWS services from a Kubernetes environment.&lt;/p&gt; &lt;p&gt;This first article lays out the reasons for using controllers and Operators, and sets up your environment for their use. A subsequent article will show how to install AWS services and how to use them within OpenShift. The ideas behind these articles, and a demo showing their steps, appear in my video &lt;a href="https://www.youtube.com/watch?v=MEKTnbeXv2Y"&gt;Using AWS Controllers for Kubernetes (ACK) with Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;So many services, so little time&lt;/h2&gt; &lt;p&gt;If you deploy any kind of code on AWS, you know that the platform offers plenty of services for your applications to consume. Perhaps you use AWS services to support your application's infrastructure—to create registries with Amazon's Elastic Container Registry (ECR) or compute instances with EC2, for instance. Or maybe you're integrating AWS services directly into your development pipeline, deploying an RDS database on the back end, or building, training, and deploying &lt;a href="https://developers.redhat.com/topics/ai-ml"&gt;machine learning&lt;/a&gt; (ML) models with Amazon SageMaker.&lt;/p&gt; &lt;p&gt;Whatever you are doing, AWS probably has a service to make your work easier, your application better, and your use of time more efficient.&lt;/p&gt; &lt;p&gt;But with so many services, how do you integrate them easily into your code? Do you write complex CloudFormations scripts to call from your &lt;a href="https://developers.redhat.com/topics/ci-cd"&gt;CI/CD&lt;/a&gt; workflows? Are you more old school and like to write wrappers in a familiar language? Or maybe it's all about APIs for you? One thing is for sure: There are a lot of options (and a lot of hoops to jump through).&lt;/p&gt; &lt;p&gt;And what if you're running Kubernetes in AWS—maybe on EKS, maybe on OpenShift, or maybe you're just rolling your own? How do you stay within the efficient, familiar, and friendly framework of coding for Kubernetes and still access AWS services without coming up with complex, confusing, and hard-to-maintain workarounds that break your workflow?&lt;/p&gt; &lt;h2&gt;It's easy: You ACK it&lt;/h2&gt; &lt;p&gt;With the growth of Kubernetes for mission-critical production workloads, AWS is a match made in heaven for Kubernetes developers. With so many resilient services, Kubernetes in AWS is a smorgasbord of functionality to improve, scale, and prepare your app for anything. Bring on Black Friday sales and Click Frenzy shopping days—Kubernetes in AWS has cloud-native efficiencies and AWS resiliency built-in.&lt;/p&gt; &lt;p&gt;And now, with AWS Controllers for Kubernetes (ACK), you can easily define and use AWS resources directly from Kubernetes. ACK allows Kubernetes users to define AWS resources using the Kubernetes API. This means you can declaratively define and create an AWS RDS database, S3 bucket, or many other resources, using the same workflow as the rest of your code. There's no need to break out and learn AWS-specific languages or processes. Instead, when an ACK controller is installed, you can use the Kubernetes API to instruct the controller to interact with the AWS service. As a bonus, Kubernetes continues to manage the service for you.&lt;/p&gt; &lt;p&gt;To enable these rich possibilities, each ACK instance is a unique Docker image available in the &lt;a href="https://gallery.ecr.aws/aws-controllers-k8s"&gt;ACK public gallery&lt;/a&gt;. An image is combined with a custom resource definition (CRD), allowing you to easily request custom resources (CR) to define the service and use it within your project. Additionally, integration with AWS's Identity and Access Management (IAM) ensures that all steps and interactions are secure and that role-based access control (RBAC) is managed transparently.&lt;/p&gt; &lt;p&gt;To understand how the controllers are built, including the generation of the artifacts, and to learn about the history of the ACK project, see the AWS blog post &lt;a href="https://aws.amazon.com/blogs/containers/aws-controllers-for-kubernetes-ack/"&gt;Introducing the AWS Controllers for Kubernetes (ACK)&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Operator, Operator, could you be so kind&lt;/h2&gt; &lt;p&gt;Although the default distribution method for ACK employs &lt;a href="https://helm.sh"&gt;Helm charts&lt;/a&gt;, a popular deployment tool on Kubernetes, we'll look at a simpler way to manage controllers through an Operator. Operators are a sleek aid to deployment and life cycle management for Kubernetes services. Publicly available Operators can be downloaded from &lt;a href="https://operatorhub.io"&gt;OperatorHub&lt;/a&gt;, a project started by Red Hat but used by many communities.&lt;/p&gt; &lt;p&gt;Operators, along with the &lt;a href="https://operatorframework.io"&gt;Operator Framework&lt;/a&gt;, make it super easy to install, manage, and maintain Kubernetes resources and applications across OpenShift clusters. The Operator Framework is an open source toolkit designed to manage Operators in an effective, automated, and scalable way.&lt;/p&gt; &lt;p&gt;So it's a no-brainer that we at Red Hat have worked hard to ensure that installing ACK service controllers with Operators is easy. We work closely with AWS engineers to ensure nothing is lost in the process. See &lt;a href="https://cloud.redhat.com/blog/attention-developers-you-can-now-easily-integrate-aws-services-with-your-applications-on-openshift"&gt;Attention developers: You can now easily integrate AWS services with your applications on OpenShift&lt;/a&gt;, a post on the Red Hat Cloud blog, for more details about that collaboration.&lt;/p&gt; &lt;h2&gt;Setup in AWS and Kubernetes&lt;/h2&gt; &lt;p&gt;Before installing a controller via OperatorHub, a cluster administrator needs only to carry out a few simple pre-installation steps in AWS to provide the controller credentials and authentication context for interacting with the AWS API.&lt;/p&gt; &lt;p&gt;Let's take a look at that process now. I'm using an OpenShift installation in AWS provided by &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/aws"&gt;Red Hat OpenShift Service on AWS&lt;/a&gt;, but you can use the Operators on any OpenShift cluster running on AWS with the &lt;a href="https://olm.operatorframework.io/"&gt;Operator Lifecycle Manager (OLM)&lt;/a&gt; installed.&lt;/p&gt; &lt;p&gt;Let's keep our installation tidy and create a namespace for our controllers. This is the namespace the Operators will expect to find when you install from OperatorHub, so it's best not to change the name after choosing it:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc new-project ack-system Now using project "ack-system" on server "https://api.rosatest.c63c.p1.openshiftapps.com:6443". You can add applications to this project with the 'new-app' command. For example, try: oc new-app rails-postgresql-example to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application: kubectl create deployment hello-node --image=k8s.gcr.io/serve_hostname&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, we need a user in IAM that can own the controllers and be our service account. We are going to attach our security principals to this account. To maintain clear lines between services, you could create a user for each of your controller Operators: one user for your S3 interactions, another for your RDS interactions, and so on. But to keep things simple for this example, we'll use the same user for all controllers:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-ini"&gt;$ aws iam create-user --user-name ack-user { "User": { "Path": "/", "UserName": "ack-user", "UserId": "AIDARDQA3BHOTGU5KGN24", "Arn": "arn:aws:iam::1234567890:user/ack-user", "CreateDate": "2022-03-24T01:24:03+00:00" } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, we need an access key ID and secret access key for this user. Record the &lt;code&gt;AccessKeyId&lt;/code&gt; and &lt;code&gt;SecretAccessKey&lt;/code&gt; strings generated by the following command, because you are going to store them in Kubernetes. Storing the keys allows the controllers to interact programmatically with the AWS resources. We will use these keys in a moment, but make sure to write them down and protect them (don't worry about my security, because my keys have been deleted):&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws iam create-access-key --user-name ack-user { "AccessKey": { "UserName": "ack-user", "AccessKeyId": "AKIARDQA3BHOVF4ZSHNW", "Status": "Active", "SecretAccessKey": "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", "CreateDate": "2022-03-24T01:24:24+00:00" } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now you need to attach the correct AWS policy for each service to the principal (user) you just created. This procedure grants the user control over the specific, correct, AWS resources.&lt;/p&gt; &lt;p&gt;Grant access by assigning a policy's Amazon Resource Name (ARN) to the user directly. As mentioned, you could attach policies in a one-for-one relationship to unique users (e.g., an EC2 ARN to the &lt;code&gt;ack-ec2-user&lt;/code&gt; user), or all policies to a single user. For our example, you are going to attach all our policies to the same user (&lt;code&gt;ack-user&lt;/code&gt;).&lt;/p&gt; &lt;p&gt;Recommended policy ARNs are provided in each service controller's GitHub repository in the &lt;code&gt;config/iam/&lt;/code&gt; directory. For instance, the EC2 controller's policy is in the following file on GitHub:&lt;/p&gt; &lt;pre&gt; https://github.com/aws-controllers-k8s/ec2-controller/blob/main/config/iam/recommended-policy-arn&lt;/pre&gt; &lt;p&gt;OK, let's connect some controllers' policies to our &lt;code&gt;ack-user&lt;/code&gt; service account:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws iam attach-user-policy \ --user-name ack-user \ --policy-arn 'arn:aws:iam::aws:policy/AmazonS3FullAccess' $ aws iam attach-user-policy \ --user-name ack-user \ --policy-arn 'arn:aws:iam::aws:policy/AmazonEC2FullAccess'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;These commands grant our &lt;code&gt;ack-user&lt;/code&gt; IAM user access to AWS S3 and EC2. If you want to install additional ACK operators for other AWS services, you need to enable those policies, too.&lt;/p&gt; &lt;p&gt;Next, you need to present the &lt;code&gt;ack-user&lt;/code&gt; secure credentials in a way that can be safely passed to the controller, so it will be allowed to make changes to the AWS service for which it is responsible. These credentials are a Kubernetes Secret and a ConfigMap, defined with some specific information. The naming of these assets is intentional and cannot be varied, or the Operator will not be able to find the credentials.&lt;/p&gt; &lt;p&gt;Place the &lt;code&gt;AccessKeyId&lt;/code&gt; and &lt;code&gt;SecretAccessKey&lt;/code&gt; values you recorded early in a file called &lt;code&gt;secrets.txt&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;AWS_ACCESS_KEY_ID=AKIARDQA3BHOVF4ZSHNW AWS_SECRET_ACCESS_KEY=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&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create a secret with these keys in the &lt;code&gt;ack-system&lt;/code&gt; namespace:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc create secret generic \ --namespace ack-system \ --from-env-file=secrets.txt ack-user-secrets secret/ack-user-secrets created&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You also need to set some environment variables for the controllers. Do this by creating a ConfigMap in the &lt;code&gt;ack-system&lt;/code&gt; namespace. Add the following to a file called &lt;code&gt;config.txt&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;ACK_ENABLE_DEVELOPMENT_LOGGING=true ACK_LOG_LEVEL=debug ACK_WATCH_NAMESPACE= AWS_REGION=ap-southeast-2 ACK_RESOURCE_TAGS=acktagged AWS_ENDPOINT_URL=&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You'll need to adjust the values to suit your own environment. Most of the values should be obvious, but it's important to keep &lt;code&gt;ACK_WATCH_NAMESPACE&lt;/code&gt; blank so that the controller can properly watch all namespaces. Additionally, you should not rename these variables, as the operators are preconfigured to use them as they are here.&lt;/p&gt; &lt;p&gt;Create the ConfigMap:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc create configmap \ --namespace ack-system \ --from-env-file=config.txt ack-user-config configmap/ack-user-config created&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Where to now?&lt;/h2&gt; &lt;p&gt;This article has you set up to use as many AWS services as you want through ACK and OperatorHub. The second article in the series will install EC2 and S3 as examples, and perform an S3 operation from Kubernetes.&lt;/p&gt; &lt;h2&gt;Share your experiences&lt;/h2&gt; &lt;p&gt;If you'd like to help, learn more, or just connect in general, head on over to the &lt;a href="http://kubernetes.slack.com"&gt;Kubernetes Slack channel&lt;/a&gt; and join us in #provider-aws to say hello to the AWS and Red Hat engineers creating the code, various ACK users, and even the occasional blog post author.&lt;/p&gt; &lt;p&gt;We're looking for more good examples of complex deployments created in AWS via ACK. If you've got a deployment you think would be made easier with ACK, or one you've already made better, let us know on the Slack channel or in the comments section below. We might showcase your work in some upcoming articles or videos.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/05/16/how-use-operators-aws-controllers-kubernetes" title="How to use Operators with AWS Controllers for Kubernetes"&gt;How to use Operators with AWS Controllers for Kubernetes&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>August Simonelli</dc:creator><dc:date>2022-05-16T07:00:00Z</dc:date></entry><entry><title type="html">Jakarta EE 10 is on its way with WildFly 27</title><link rel="alternate" href="http://www.mastertheboss.com/java-ee/jakarta-ee/jakarta-ee-10-is-on-its-way-with-wildfly-27/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/java-ee/jakarta-ee/jakarta-ee-10-is-on-its-way-with-wildfly-27/</id><updated>2022-05-16T06:49:09Z</updated><content type="html">WildFly 27 (Alpha) is now available. On the the top features of this releases is the preview support for some of Jakarta EE 10 features plus several product enhancement. This article launches you on a tour of this new release by focusing on fundamentals. Jakarta EE 10 status in WildFly WildFly 27 Alpha is the ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>How to organize JFR data with recording labels in Cryostat 2.1</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/05/12/how-organize-jfr-data-recording-labels-cryostat-21" /><author><name>Janelle Law</name></author><id>0f799239-8a34-4447-9021-f1f0b8b2be25</id><updated>2022-05-12T07:00:00Z</updated><published>2022-05-12T07:00:00Z</published><summary type="html">&lt;p&gt;With the tech preview release of &lt;a href="https://cryostat.io"&gt;Cryostat&lt;/a&gt; 2.1, users can attach metadata or custom labels to &lt;a href="https://developers.redhat.com/blog/2020/08/25/get-started-with-jdk-flight-recorder-in-openjdk-8u#"&gt;JDK flight recordings&lt;/a&gt; that monitor &lt;a href="https://developers.redhat.com/topics/containers"&gt;containerized&lt;/a&gt; &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; applications, and can manage those recordings using Cryostat. Recording labels can identify recordings in queries and perform actions on multiple recordings containing the same label. This article shows how to add and edit metadata labels on your JDK flight recordings, including the recordings managed through &lt;a href="https://developers.redhat.com/articles/2021/11/09/automating-jdk-flight-recorder-containers"&gt;automated rules&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Add a recording label to a JDK flight recording&lt;/h2&gt; &lt;p&gt;Navigate to the &lt;strong&gt;Recordings&lt;/strong&gt; tab on the Cryostat console and select a target JVM from the drop-down menu. Click &lt;strong&gt;Create&lt;/strong&gt; to create a custom flight recording (Figure 1). When creating the flight recording, expand the &lt;strong&gt;Show metadata options&lt;/strong&gt; form section. Click &lt;strong&gt;Add Label&lt;/strong&gt; to add a key-value label pair to the recording. For more details about creating recordings, see the &lt;a href="https://cryostat.io/guides/#startstop-a-recording"&gt;Cryostat guides&lt;/a&gt;.&lt;/p&gt; &lt;figure role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/metadata-label-1_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/metadata-label-1_0.png?itok=ETHOR8ws" width="1440" height="823" alt="A custom flight recording can be tracked through custom labels." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: A custom flight recording can be tracked through custom labels. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;The new recording will appear in the &lt;strong&gt;Recordings&lt;/strong&gt; tab with your custom label, along with default labels containing information about the selected recording template, as shown in Figure 2.&lt;/p&gt; &lt;figure role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/metadata-label-2.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/metadata-label-2.png?itok=Td6iPTIA" width="1440" height="728" alt="The Active Recordings table shows the labels on each recording." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: The Active Recordings table shows the labels on each recording. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;h2&gt;Edit recording labels for a JDK flight recording&lt;/h2&gt; &lt;p&gt;Recording labels can also be edited after recordings have been created or re-uploaded to archives. For instance, it looks like the custom label in our example contains a typo. You can fix it by editing the label.&lt;/p&gt; &lt;p&gt;Click the ellipsis menu beside the recording table entry, then click &lt;strong&gt;Edit Metadata&lt;/strong&gt;. The labels section will appear as a form where you can add, edit, or delete existing labels. Click &lt;strong&gt;Save&lt;/strong&gt; to save your edited labels, as shown in Figure 3.&lt;/p&gt; &lt;figure role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/metadata-label-3.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/metadata-label-3.png?itok=-FF9scuN" width="1440" height="728" alt="The value of a label has been edited." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: The value of a label has been edited. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;The recording labels should now be updated in the &lt;strong&gt;Active Recordings&lt;/strong&gt; table, as shown in Figure 4.&lt;/p&gt; &lt;figure role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/metadata-label-4.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/metadata-label-4.png?itok=Sw62SIU2" width="1440" height="728" alt="The Active Recordings table shows the updated labels." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: The Active Recordings table shows the updated labels. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;On the &lt;strong&gt;Active Recordings&lt;/strong&gt; table, click the checkbox next to the recording, then click &lt;strong&gt;Archive&lt;/strong&gt; to archive your recording.&lt;/p&gt; &lt;p&gt;The archived recording also copies the labels from the active recording, as shown in Figure 5. This means you can easily find the archived recordings associated with an active recording by searching for the metadata labels applied to the active recording. You can also add additional labels to any recording uploaded to the Cryostat archives. The labels are preserved for as long as the recording remains in the archives.&lt;/p&gt; &lt;figure role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/metadata-label-5.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/metadata-label-5.png?itok=1EBW7Bbr" width="1440" height="728" alt="Labels are also shown for each recording in the Archived Recordings tab." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: Labels are also shown for each recording in the Archived Recordings tab. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;h2&gt;Labeling recordings generated with automated rules&lt;/h2&gt; &lt;p&gt;Automated rules, introduced in the article &lt;a href="https://developers.redhat.com/articles/2021/11/09/automating-jdk-flight-recorder-containers"&gt;Automating JDK Flight Recorder in containers&lt;/a&gt;, simplify the tracking and management of multiple JDK flight recordings. An automated rule automatically applies a metadata label to indicate the name of the automated rule that created that recording. For example, if your automated rule was named &lt;code&gt;my_automated_rule&lt;/code&gt;, all recordings generated with that rule will contain the metadata label &lt;code&gt;Rule: my_automated_rule&lt;/code&gt;. When these recordings are archived, the labels are preserved to help you easily locate all of your recordings generated by &lt;code&gt;my_automated_rule&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This article has explained how to add and edit recording metadata labels for a single JDK flight recording, or for multiple recordings if they are managed by an automated rule. Automated rules also apply metadata labels to each recording they create.&lt;/p&gt; &lt;p&gt;In a future article in this series, you will learn to search for and operate on recordings using these labels. For more information about Cryostat, visit the project's &lt;a href="https://cryostat.io/get-started/"&gt;getting started page&lt;/a&gt;. For questions, comments and feedback, feel free to connect with us on &lt;a href="https://github.com/cryostatio"&gt;GitHub&lt;/a&gt; or join our &lt;a href="https://groups.google.com/g/cryostat-development"&gt;mailing list&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/05/12/how-organize-jfr-data-recording-labels-cryostat-21" title="How to organize JFR data with recording labels in Cryostat 2.1"&gt;How to organize JFR data with recording labels in Cryostat 2.1&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Janelle Law</dc:creator><dc:date>2022-05-12T07:00:00Z</dc:date></entry><entry><title type="html">WildFly Preview 27 Alpha1 is released</title><link rel="alternate" href="https://wildfly.org//news/2022/05/12/WildFlyPreview27-Alpha1-Released/" /><author><name>Brian Stansberry</name></author><id>https://wildfly.org//news/2022/05/12/WildFlyPreview27-Alpha1-Released/</id><updated>2022-05-12T00:00:00Z</updated><content type="html">Today we have released a 27.0.0.Alpha1 version of WildFly Preview. This release serves as a milestone on our way toward support for Jakarta EE 10 in WildFly Preview, and eventually in standard WildFly. As discussed in my January , the main focus of the WildFly developers as we work on WildFly 27 is implementing Jakarta EE 10 support. That work has now reached a point in WildFly Preview where it’s useful to evaluate WildFly Preview as a compatible implementation of the new . In order to help with bringing the EE 10 Core Profile specification to completion, we’ve released WildFly Preview 27.0.0.Alpha1. Note that we are not adding 27.0.0.Alpha1 binaries for standard WildFly to . Standard WildFly is still built with the Jakarta EE 8 APIs, but we plan to switch to EE 10 in our main branch soon, and we will not be doing a standard WildFly 27 Final release that supports EE 8. So, there is not much purpose looking at 27.0.0.Alpha1 for standard WildFly. (Its binaries can be found in the .) We’re also not releasing quickstarts or cloud images for this release. WHAT’S NEW? A couple of noteworthy items in this release are support for CDI 4.0 (via Weld 5), including CDI Lite, along with the much-asked-for transition from Hibernate 5.3 to Hibernate 6. The full list of issues resolved is available . JAVA SE SUPPORT You can run 27.0.0.Alpha1 on Java SE 11 or Java SE 17. The WildFly project no longer supports Java SE 8 in our feature releases, although our planned 26.1.1 and 26.1.2 bug fix releases will support SE 8. STANDARDS SUPPORT The 27.0.0.Alpha1 release is not a compatible implementation of Jakarta EE 8 or 9.1, nor is it a compatible implementation of MicroProfile Platform 4.1 or 5. Strict specification compliance wasn’t a focus of this alpha release, other than a desire to be compatible with the EE 10 Core Profile once that specification is released. UPCOMING CHANGES As discussed in my January , WildFly 26.1 was the last WildFly feature release that will support Java SE 8, Jakarta EE 8 and MicroProfile 4.1, while WildFly Preview 26.1 was the last release that will support Jakarta EE 9.1. The WildFly 27 release will require Java SE 11 or higher and will support Jakarta EE 10 and MicroProfile APIs based on the jakarta.* package namespace. We plan to do a WildFly 26.1.1 bug fix release in May. Something different from previous releases is we also intend to do a WildFly 26.1.2 bug fix release in the July-August time frame. The aim of that release will be to deliver any critical fixes we’ve discovered, particularly security related items. We recognize that moving on from SE 8 and EE 8 may be a substantial task for many of our users, so we want to help ease that transition by providing an extra bug fix release. ENJOY! Thank you for your continued support of WildFly. We’d love to hear your feedback at the .</content><dc:creator>Brian Stansberry</dc:creator></entry><entry><title type="html">How to add users using file-based strategy in PAM/DM 7.12</title><link rel="alternate" href="https://blog.kie.org/2022/05/users-file-strategy-rhpam.html" /><author><name>Archana Krishnan</name></author><id>https://blog.kie.org/2022/05/users-file-strategy-rhpam.html</id><updated>2022-05-11T16:20:25Z</updated><content type="html">Issue Identified: Custom Users/Roles not created in RHPAM 7.12.1/EAP 7.4.1. Sample of invalid user.xml: &lt;?xml version="1.0" ?&gt; &lt;identity xmlns="urn:elytron:1.0"&gt; &lt;attributes&gt; &lt;name="roles" value="kie-server"&gt;&lt;/attribute&gt; &lt;attribute name="roles" value="rest-all"&gt;&lt;/attribute&gt; &lt;attribute name="roles" value="admin"&gt;&lt;/attribute&gt; &lt;attribute name="roles" value="kiemgmt"&gt;&lt;/attribute&gt; &lt;attribute name="roles" value="Administrators"&gt;&lt;/attribute&gt; &lt;attribute name="roles" value="user"&gt;&lt;/attribute&gt; &lt;/attributes&gt;&lt;/identity&gt;$ Error in logs: 23:35:20,692 ERROR [org.jboss.as.controller.management-operation] (CLI command executor) WFLYCTL0013: Operation (“set-password”) failed – address: () – failure description: “WFLYCTL0216: Management resource ‘[ (\”subsystem\” =&gt; \”elytron\”), (\”filesystem-realm\” =&gt; \”ApplicationRealm\”) ]’ not found” The batch failed with the following error (you are remaining in the batch editing mode to have a chance to correct the error): WFLYCTL0062: Composite operation failed and was rolled back. Steps that failed: Step: step-11 Operation: /subsystem=elytron/filesystem-realm=ApplicationRealm:set-password(identity=pamAdmin, clear={password=’testAdmin’}) Failure: WFLYCTL0216: Management resource ‘‘ not found Warning in logs: 23:36:18,734 WARN [org.jboss.modules.define] (ServerService Thread Pool -- 86) Failed to define class org.jboss.resteasy.microprofile.config.ServletConfigSourceImpl in Module "org.jboss.resteasy.resteasy-jaxrs" version 3.15.1.Final-redhat-00001 from local module loader @21edd891 (finder: local module finder @de579ff (roots: /opt/eap/modules,/opt/eap/modules/system/layers/openshift,/opt/eap/modules/system/layers/base/.overlays/layer-base-jboss-eap-7.4.1.CP,/opt/eap/modules/system/layers/base,/opt/eap/modules/system/add-ons/keycloak)): java.lang.NoClassDefFoundError: Failed to link org/jboss/resteasy/microprofile/config/ServletConfigSourceImpl (Module "org.jboss.resteasy.resteasy-jaxrs" version 3.15.1.Final-redhat-00001 from local module loader @21edd891 (finder: local module finder @de579ff (roots: /opt/eap/modules,/opt/eap/modules/system/layers/openshift,/opt/eap/modules/system/layers/base/.overlays/layer-base-jboss-eap-7.4.1.CP,/opt/eap/modules/system/layers/base,/opt/eap/modules/system/add-ons/keycloak))): org/eclipse/microprofile/config/spi/ConfigSource at java.base/java.lang.ClassLoader.defineClass1(Native Method) Other errors if an invalid user/roles properties file is provided: sh-4.4$ /opt/eap/bin/elytron-tool.sh filesystem-realm --users-file /home/jboss/custom/application-users.properties --roles-file /home/jboss/custom/application-roles.properties --output-location /opt/eap/standalone/configuration/kie-fs-realm-users --filesystem-realm-name kie-fs-realmusers --debug WARNING: No roles were found for user WARNING: Roles were found for user , but user was not defined. WARNING: No roles were found for user Exception encountered executing the command: java.lang.IndexOutOfBoundsException at java.base/java.lang.Character.offsetByCodePoints(Character.java:8699) WARNING: No password was found for user WARNING: No roles were found for user WARNING: No roles were found for user Exception encountered executing the command: java.lang.IndexOutOfBoundsException SOLUTION The following steps will help resolve the above issues: * Patch RHPAM 7.12.1 with EAP 7.4.4 STEP 1/5: FROM registry.redhat.io/rhpam-7/rhpam-kieserver-rhel8:7.12.1-3 STEP 2/5: COPY jboss-eap-7.4.4-patch.zip /tmp/jboss-eap-7.4.4-patch.zip --&gt; Using cache f9926b6ad308871c77bf3f1e650104f1c64f249b487613e4181d8e1e9ca9cd07 --&gt; f9926b6ad30 STEP 3/5: USER root --&gt; Using cache 15639841591027c9db7a4056ea69b51252d72dac6a2704528533d5b0ce03496f --&gt; 15639841591 STEP 4/5: RUN $JBOSS_HOME/bin/jboss-cli.sh --command="patch apply /tmp/jboss-eap-7.4.4-patch.zip --override-modules" ; rm /tmp/jboss-eap-7.4.4-patch.zip { "outcome" : "success", "result" : {} } STEP 5/5: USER 185 COMMIT image-registry.openshift-image-registry.svc:5000/op2/rhpam-kieserver-rhel8-custom:7.12.1-test --&gt; 85398f6feb7 Successfully tagged image-registry.openshift-image-registry.svc:5000/op2/rhpam-kieserver-rhel8-custom:7.12.1-test 85398f6feb78e1485f53a2ee154d20d33b2b7457a13325cfc9a928c7a7592ce3 * Validate EAP version [jboss@4c610ade4e51 eap]$ ls JBossEULA.txt LICENSE.txt appclient bin docs domain jboss-modules.jar jolokia.jar migration modules standalone version.txt welcome-content [jboss@4c610ade4e51 eap]$ more version.txt Red Hat JBoss Enterprise Application Platform - Version 7.4.4.GA * Update the custom application-users.properties and application-roles.properties file to include Realm name: Sample application-users.properties: Sample application-roles.properties: * Command to update custom users/roles file through elytron-tool.sh echo "START - enable-users" /opt/eap/bin/elytron-tool.sh filesystem-realm --users-file /home/jboss/custom/application-users.properties --roles-file /home/jboss/custom/application-roles.properties --output-location /opt/kie/data/kie-fs-realm-users find /opt/kie/data/kie-fs-realm-users -name *.xml -exec sed -i 's/&lt;attribute name="roles"/&lt;attribute name="role"/g' {} \; echo "END - enable-users" * Expected user.xml generated in output-location (/opt/kie/data/kie-fs-realm-users): &lt;?xml version="1.0" ?&gt; &lt;identity xmlns="urn:elytron:1.0"&gt; &lt;credentials&gt; &lt;password algorithm="digest-md5" format="base64"&gt;Ag9pbnRlZ3JhdGlvblVzZXIQQXBwbGljYXRpb25SZWFsbSjAetOv+11Kg3GFrzK+r98&lt;/password&gt; &lt;/credentials&gt; &lt;attributes&gt; &lt;attribute name="role" value="kie-server"&gt;&lt;/attribute&gt; &lt;attribute name="role" value="rest-all"&gt;&lt;/attribute&gt; &lt;attribute name="role" value="admin"&gt;&lt;/attribute&gt; &lt;attribute name="role" value="kiemgmt"&gt;&lt;/attribute&gt; &lt;attribute name="role" value="Administrators"&gt;&lt;/attribute&gt; &lt;attribute name="role" value="user"&gt;&lt;/attribute&gt; &lt;/attributes&gt;&lt;/identity&gt;sh-4.4$ ROOT CAUSE RHPAM 7.12.1 paired with EAP 7.4.1 does not create a valid XML file for kie-fs-realm users/roles. Reference RedHat support case – The post appeared first on .</content><dc:creator>Archana Krishnan</dc:creator></entry><entry><title>RHEL 8.6: What's new and how to upgrade</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/05/11/rhel-86-whats-new-and-how-upgrade" /><author><name>Nikhil Mungale, Alex Krikos</name></author><id>b6702212-ce67-45a2-9500-1161fe43cf71</id><updated>2022-05-11T13:45:00Z</updated><published>2022-05-11T13:45:00Z</published><summary type="html">&lt;p&gt;Version 8.6 of &lt;a href="https://developers.redhat.com/products/rhel"&gt;Red Hat Enterprise Linux&lt;/a&gt; is now generally available, and includes a number of features and upgrade paths that will benefit developers and &lt;a href="https://developers.redhat.com/topics/devops"&gt;DevOps&lt;/a&gt; teams. This article covers some of the most notable improvements. Please refer to the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/8.6_release_notes/index"&gt;release notes&lt;/a&gt; for a comprehensive list of changes.&lt;/p&gt; &lt;h2&gt;Support for newer versions of language runtimes&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/topics/php"&gt;PHP 8.0&lt;/a&gt; provides several bug fixes and enhancements, such as the use of structured metadata syntax, newly named arguments that are order-independent, and improved performance for Just-In-Time compilation.&lt;/li&gt; &lt;li&gt;Perl 5.32 provides a number of bug fixes and enhancements, including Unicode version 13, a new experimental infix operator, and faster feature checks.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Red Hat Enterprise Linux for the edge&lt;/h2&gt; &lt;p&gt;Red Hat Enterprise Linux 8.6 now supports automatic provisioning and onboarding for &lt;a href="https://developers.redhat.com/topics/edge-computing"&gt;edge&lt;/a&gt; images. With this update, customers can build Red Hat Enterprise Linux for the edge, provision it, use the &lt;a href="https://fidoalliance.org/specs/FDO/FIDO-Device-Onboard-RD-v1.0-20201202.html"&gt;FIDO Device Onboarding&lt;/a&gt; (FDO) process to automatically provision and onboard edge devices, and exchange data with other devices and systems connected on the network.&lt;/p&gt; &lt;h2&gt;New system roles&lt;/h2&gt; &lt;p&gt;Red Hat Enterprise Linux&lt;strong&gt; &lt;/strong&gt;8.6 has new system roles that enable seamless &lt;a href="https://developers.redhat.com/topics/automation"&gt;automation&lt;/a&gt; for system administrators. Here is a list of new system roles:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;High availability (HA) cluster system role&lt;/strong&gt;: This role helps create and manage secure, stable HA clusters. It also enables DevOps teams to have better control over managing multiple clusters.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Enhanced network system role:&lt;/strong&gt; This role helps DevOps teams create secure connections (including over Wi-Fi) along with robust firewall rules.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;WebConsole role:&lt;/strong&gt; This role automates the installation and configuration of the Red Hat Enterprise Linux web console, including the tasks of installing the web console package, starting and enabling the web console, and configuring settings such as idle timeout.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Upgrading to Red Hat Enterprise Linux 8&lt;/h2&gt; &lt;p&gt;There are a variety of upgrade paths in version 8.6:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;In-place upgrades are supported from Red Hat Enterprise Linux versions 6 or 7 to version 8.&lt;/li&gt; &lt;li&gt;It is now possible to perform an in-place upgrade with SAP HANA on AWS pay-as-you-go approach instances using &lt;a href="https://access.redhat.com/products/red-hat-update-infrastructure"&gt;Red Hat Update Infrastructure&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;It is now possible to enable &lt;a href="https://access.redhat.com/articles/rhel-eus"&gt;Extended Update Support&lt;/a&gt; and E4S repositories during an in-place upgrade.&lt;/li&gt; &lt;li&gt;Customers currently using CentOS 8 or Oracle Linux 8 can convert their operating system to Red Hat Enterprise Linux 8 using the Red Hat-supported &lt;code&gt;Convert2RHEL&lt;/code&gt; utility. For more information, please see &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/converting_from_an_rpm-based_linux_distribution_to_rhel/index"&gt;Converting from an RPM-based Linux distribution to Red Hat Enterprise Linux.&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Red Hat customers can get direct access to Red Hat Enterprise Linux 8.6 from the &lt;a href="https://access.redhat.com/products/red-hat-enterprise-linux/"&gt;Red Hat Enterprise Linux Customer Portal&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/05/11/rhel-86-whats-new-and-how-upgrade" title="RHEL 8.6: What's new and how to upgrade"&gt;RHEL 8.6: What's new and how to upgrade&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Nikhil Mungale, Alex Krikos</dc:creator><dc:date>2022-05-11T13:45:00Z</dc:date></entry><entry><title>How to build automated JFR rules with Cryostat 2.1's new UI</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/05/11/how-build-automated-jfr-rules-cryostat-21s-new-ui" /><author><name>Andrew Azores</name></author><id>ab6ad892-9bbe-4106-b3f4-70a4e385785e</id><updated>2022-05-11T07:00:00Z</updated><published>2022-05-11T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://cryostat.io"&gt;Cryostat&lt;/a&gt; is a tool for managing JDK Flight Recorder data on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. Cryostat 2.1, the most recent version of the software, has a brand-new user interface for the automated rules that were previously introduced as an API feature in Cryostat 2.0. It is now much easier to manage &lt;a href="https://docs.oracle.com/javacomponents/jmc-5-4/jfr-runtime-guide/about.htm"&gt;JDK Flight Recording&lt;/a&gt; (JFR) on a large scale for many &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; applications.&lt;/p&gt; &lt;h2&gt;The power of automated rules&lt;/h2&gt; &lt;p&gt;Automated rules trigger JFRs against target JVMs, offering powerful and flexible match expressions to determine which applications each rule applies to. These match expressions can refer to various properties of the target applications, such as the pod name (which can be compared using direct string equality or regular expressions), JMX port number, and any &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;OpenShift&lt;/a&gt; or Kubernetes labels and annotations present on the pod.&lt;/p&gt; &lt;p&gt;When a rule is created, Cryostat selects all the applications matched by the expression and starts a new recording using the JFR event template defined by the rule. The same thing happens whenever a new target application instance is discovered: Cryostat tests whether the new application instance matches an expression in a rule that has been previously created and, if so, starts a new recording using the event template.&lt;/p&gt; &lt;p&gt;Additionally, an automated rule can include options for copying the recordings out of the target application memory and into Cryostat's archives. The rule can specify how often the recording data should be copied and how many previous copies of this archived data to preserve, pruning the oldest.&lt;/p&gt; &lt;h2&gt;The new user interface&lt;/h2&gt; &lt;p&gt;A new user interface (UI) makes it easier than ever to get started with this powerful feature. Not only does the form view simplify interaction with the API by providing typed inputs (number pickers for durations, for instance), but it also includes a match expression wizard to help users craft the perfect expression to match the exact set of target applications they intend to observe (Figure 1).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image2_2.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/image2_2.png?itok=YmSPHl5o" width="1440" height="820" alt="The UI for automated rules provides fields and other elements to control every aspect of the rule." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. The UI for automated rules provides fields and other elements to control every aspect of the rule. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: The UI for automated rules provides fields and other elements to control every aspect of the rule.&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;When you select a target, the match expression wizard provides a simple example of a match expression that could be used to match this target. This is meant simply as a hint to remind you of the match expression syntax.&lt;/p&gt; &lt;p&gt;The right side split portion of the view displays the selected target as a JSON structure. This shows you all of the information about the target application that you can refer to within the match expression (Figure 2).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image1_6.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/image1_6.png?itok=5A2rjZ9V" width="1440" height="820" alt="On the right side of the page, all the parameters of an automated rule appear as JSON." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2. On the right side of the page, all the parameters of an automated rule appear as JSON. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: On the right side of the page, all the parameters of an automated rule appear as JSON.&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Once you have an idea of an expression that should match the applications you want, enter it into the match expression field. The UI will be updated to show a color-coded response to indicate whether your expression matches the currently selected target:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Green&lt;/strong&gt; indicates that the expression matches the selected application.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Yellow&lt;/strong&gt; indicates that the expression given is a valid expression, but does not match the selected application.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Red&lt;/strong&gt; indicates that the given expression is invalid, most likely due to bad syntax.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If needed, adjust your match expression so that the indicator turns green and the expression matches the target. Next, select another target application that you want to apply the same automated rule to, and verify that the indicator is still green. If not, adjust the match expression again until it is green for both applications. You can also select an application that you do not want to match and verify that the indicator is yellow.&lt;/p&gt; &lt;p&gt;In Figure 3, I have written &lt;code&gt;target.labels.deployment == "quarkus-test"&lt;/code&gt; the match expression. The green color and checkmark indicate that this expression matches the selected target application.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image3_3.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/image3_3.png?itok=PhldAgBY" width="1440" height="820" alt="A checkmark and green highlighting show a rule that matches a target application." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3. A checkmark and green highlighting show a rule that matches a target application. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: A checkmark and green highlighting show a rule that matches a target application.&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;For more details and information about the match expression syntax, the automated rules API, and some example use cases, please refer to my previous article on Red Hat Developer, &lt;a href="https://developers.redhat.com/articles/2021/11/09/automating-jdk-flight-recorder-containers"&gt;Automating JDK Flight Recorder in containers&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;After you submit this form, you will return to the &lt;strong&gt;Automated Rules&lt;/strong&gt; view and should see the definition of your new rule appear in the table. Cryostat will immediately check all known target applications, evaluate whether the match expression applies to them, and, if so, start a recording using the defined settings. When future target applications are discovered, they will also be automatically checked against the match expression, with a recording started if necessary.&lt;/p&gt; &lt;h2&gt;Up next: How to label a Cryostat recording&lt;/h2&gt; &lt;p&gt;Cryostat 2.1 has a new feature for adding labels to recordings. When a recording is started by an automated rule, it automatically gains a label specifying the name of the rule responsible for starting the recording. This label also follows the recording into the archives if it is copied there. Watch this space for an article coming soon focusing on this feature.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/05/11/how-build-automated-jfr-rules-cryostat-21s-new-ui" title="How to build automated JFR rules with Cryostat 2.1's new UI"&gt;How to build automated JFR rules with Cryostat 2.1's new UI&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Andrew Azores</dc:creator><dc:date>2022-05-11T07:00:00Z</dc:date></entry><entry><title type="html">Vlog: WildFly Datasource configuration on OpenShift</title><link rel="alternate" href="https://www.youtube.com/watch?v=4acHNgSdwFk" /><author><name>Yeray Borges</name></author><id>https://www.youtube.com/watch?v=4acHNgSdwFk</id><updated>2022-05-11T00:00:00Z</updated><dc:creator>Yeray Borges</dc:creator></entry><entry><title>Introducing Red Hat OpenShift extension for Docker Desktop</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/05/10/introducing-red-hat-openshift-extension-docker-desktop" /><author><name>Stevan Le Meur</name></author><id>a57251d9-5020-48f2-b0f4-69282d90303a</id><updated>2022-05-10T15:10:00Z</updated><published>2022-05-10T15:10:00Z</published><summary type="html">&lt;p&gt;Today we are announcing our new &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; extension for Docker Desktop, which helps developers with all of the different steps required to get an application running on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. The extension aims to provide a bridge from your local environment to the environments where you run your applications.&lt;/p&gt; &lt;ul&gt; &lt;li aria-level="1"&gt;Get started easily with deploying and testing your application on Kubernetes.&lt;/li&gt; &lt;li aria-level="1"&gt;Ensure your applications are secure and follow best practices.&lt;/li&gt; &lt;li aria-level="1"&gt;Build your application with the target runtime environment in mind, knowing all the various prerequisites will be handled.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;The Red Hat OpenShift extension for Docker Desktop&lt;/h2&gt; &lt;p&gt;The Red Hat OpenShift extension for Docker Desktop lets developers working with OpenShift deploy and test their applications with ease.&lt;/p&gt; &lt;p&gt;Simply choose your target environment and the project you want to deploy to and select the application image from the ones available on Docker Desktop. Then, the extension takes care of deploying the application on OpenShift. Typically, you'll use this extension once you have already built your application and containerized it.&lt;/p&gt; &lt;p&gt;Let’s see a &lt;a href="https://youtu.be/NhamWN1PisY"&gt;quick demo&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Installation&lt;/h2&gt; &lt;p&gt;Starting with version 4.8, Docker Desktop provides new Extensions capabilities. You can find the Extensions Marketplace under the new section introduced in the sidebar.&lt;/p&gt; &lt;p&gt;Click "Add Extensions" to browse all available extensions for Docker Desktop. Locate the Red Hat OpenShift extension in the list. You can then install it with a single click.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; The extension works only with Red Hat OpenShift.&lt;/p&gt; &lt;h2&gt;Simplified Kubernetes development&lt;/h2&gt; &lt;p&gt;At Red Hat, we want to simplify the developer experience when using Kubernetes as the runtime environment for their applications.&lt;/p&gt; &lt;p&gt;Testing applications on Kubernetes—and testing in an environment as close as possible to the one used in production—can be a challenge. Getting an environment set up can also be difficult, and once that environment is available, we are exposed to new concepts and new paradigms. On top of that, there is also additional overhead to worry about with the extra config files we need to manage.&lt;/p&gt; &lt;p&gt;Even if we have the commonality of &lt;a href="https://developers.redhat.com/topics/containers"&gt;containers&lt;/a&gt;, getting them to run on Kubernetes can be a challenge. It’s not as easy as a “build and refresh,” and the turnarounds are getting slower.&lt;/p&gt; &lt;p&gt;This is why we build &lt;a href="https://developers.redhat.com/topics/developer-tools"&gt;developer tools&lt;/a&gt; to reduce friction and simplify the experience of testing and working with Kubernetes. This is what the new Red Hat OpenShift extension for Docker Desktop is all about!&lt;/p&gt; &lt;h2&gt;Key features&lt;/h2&gt; &lt;p&gt;The Red Hat OpenShift extension for Docker Desktop (Figure 1) provides the capabilities to:&lt;/p&gt; &lt;ul&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Detect Kubernetes environments: &lt;/strong&gt; Scan defined kubeconfigs on your local environment and preselect your current default Kubernetes environment. You can also easily switch from one environment to another.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Log in into clusters: &lt;/strong&gt;Directly connect to a new Kubernetes environment not yet configured on your local workstation.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;List projects (namespace): &lt;/strong&gt;Browse and select the project in which you want to deploy your application.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Select container images:&lt;/strong&gt; Pick and choose any container image you already have built and deployed on a container registry.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Deploy container images: &lt;/strong&gt; A container image gets deployed by building the necessary resources with the automatic creation of the route to expose the application outside of the cluster. Once deployed, the application opens in a new browser tab.&lt;/li&gt; &lt;/ul&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift-docker-desktop-extension.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/openshift-docker-desktop-extension.png?itok=9JsYL66x" width="600" height="484" alt="OpenShift Extension for Docker Desktop" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: The Red Hat OpenShift extension for Docker Desktop user interface.&lt;/figcaption&gt; &lt;/figure&gt; &lt;h2&gt;Future roadmap&lt;/h2&gt; &lt;p&gt;In the future, we plan to add more capabilities, including:&lt;/p&gt; &lt;ul&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Easy access to Kubernetes and OpenShift with the Developer Sandbox:&lt;/strong&gt; Leverage the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt; to access OpenShift environments in the cloud at no cost, with zero setup needed.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Watch mode:&lt;/strong&gt; Watch for changes in source code to automatically build, push, and deploy the application on the development cluster.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Learn more and get involved&lt;/h2&gt; &lt;p&gt;If you’d like to learn more about the OpenShift extension for Docker Desktop, visit the following links:&lt;/p&gt; &lt;ul&gt; &lt;li aria-level="1"&gt;&lt;a href="https://github.com/redhat-developer/openshift-dd-ext"&gt;OpenShift Docker Desktop extension repository&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://www.docker.com/blog/docker-extensions-discover-build-integrate-new-tools-into-docker-desktop"&gt;Docker Extensions: Discover, Build and Integrate New Tools into Docker Desktop&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;To share your feedback, suggestions, ideas, or report an issue, use &lt;a href="https://github.com/redhat-developer/openshift-dd-ext"&gt;the GitHub repository&lt;/a&gt; to start a discussion or file a bug.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/05/10/introducing-red-hat-openshift-extension-docker-desktop" title="Introducing Red Hat OpenShift extension for Docker Desktop"&gt;Introducing Red Hat OpenShift extension for Docker Desktop&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Stevan Le Meur</dc:creator><dc:date>2022-05-10T15:10:00Z</dc:date></entry><entry><title type="html">London OpenShift User Group - Talking Architecture Shop</title><link rel="alternate" href="http://www.schabell.org/2022/05/london-openshift-user-group-talking-architecture-shop.html" /><author><name>Eric D. Schabell</name></author><id>http://www.schabell.org/2022/05/london-openshift-user-group-talking-architecture-shop.html</id><updated>2022-05-10T15:00:00Z</updated><content type="html">My second trip this year takes me to London for some fun later this week at Devoxx UK 2022 and a chance to speak with our customers at the London OpenShift User Group. As the , Tuesday 10th May we have a special meeting of the London OpenShift User Group featuring: * Enterprise Portfolio Architecture - the open source way * Uncover the genius within your ranks - A live stream of the Keynote presentation from Red Hat Summit in Boston featuring Paul Cormier (President and CEO), Stefanie Chiras (Senior VP) and Matt Hicks (Executive VP) Below you'll find the slides from my talk. The event kicks off with a welcome and then I'll present the following, with slides included here for your viewing pleasure: TALKING ARCHITECTURE SHOP - EXPLORING OPEN SOURCE SUCCESS AT SCALE You've heard of large scale open source architectures, but have you ever wanted to take a serious look at these real life enterprise implementations that scale? This session takes attendees on a tour of multiple use cases covering enterprise challenges like integration, optimisation, cloud adoption, hybrid cloud management, healthcare, retail, manufacturing, financial services, and much more. Not only are these architectures interesting, but they are successful real life implementations featuring open source technologies and power many of your own online experiences. The attendee departs this session with a working knowledge of how to map general open source technologies to their solutions. Material covered is available freely online and attendees can use these solutions as starting points for aligning to their own solution architectures. Thanks for the time and lending me your ears!</content><dc:creator>Eric D. Schabell</dc:creator></entry></feed>
